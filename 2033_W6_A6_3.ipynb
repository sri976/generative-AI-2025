{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7q2qBC7dH836+Sz3MLG+6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sri976/generative-AI-2025/blob/main/2033_W6_AS6_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5PPwh6_jtiU",
        "outputId": "8b2072d7-842d-42cf-843a-401e13d5f376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGGZ8zULd6Rb",
        "outputId": "58880c42-cb47-4784-9eba-f97bff135060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 25413814321152.0000 - mae: 4708655.0000 - val_loss: 30129992499200.0000 - val_mae: 5007536.5000\n",
            "Epoch 2/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 26320283107328.0000 - mae: 4789295.5000 - val_loss: 30129988304896.0000 - val_mae: 5007536.0000\n",
            "Epoch 3/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 24566061596672.0000 - mae: 4651378.5000 - val_loss: 30129988304896.0000 - val_mae: 5007535.5000\n",
            "Epoch 4/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 25449103097856.0000 - mae: 4727315.0000 - val_loss: 30129984110592.0000 - val_mae: 5007535.5000\n",
            "Epoch 5/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 24038837583872.0000 - mae: 4587627.5000 - val_loss: 30129977819136.0000 - val_mae: 5007535.5000\n",
            "Epoch 6/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 24697039224832.0000 - mae: 4668420.5000 - val_loss: 30129969430528.0000 - val_mae: 5007535.0000\n",
            "Epoch 7/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 25156690903040.0000 - mae: 4687569.5000 - val_loss: 30129963139072.0000 - val_mae: 5007534.0000\n",
            "Epoch 8/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 24539771699200.0000 - mae: 4633452.5000 - val_loss: 30129948459008.0000 - val_mae: 5007532.5000\n",
            "Epoch 9/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 25440286670848.0000 - mae: 4732022.5000 - val_loss: 30129929584640.0000 - val_mae: 5007531.0000\n",
            "Epoch 10/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 25155004792832.0000 - mae: 4701927.0000 - val_loss: 30129910710272.0000 - val_mae: 5007529.0000\n",
            "Epoch 11/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 24333617463296.0000 - mae: 4615892.0000 - val_loss: 30129877155840.0000 - val_mae: 5007526.0000\n",
            "Epoch 12/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 25168715972608.0000 - mae: 4687129.5000 - val_loss: 30129845698560.0000 - val_mae: 5007522.5000\n",
            "Epoch 13/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 26251209211904.0000 - mae: 4783031.0000 - val_loss: 30129805852672.0000 - val_mae: 5007519.0000\n",
            "Epoch 14/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 26001916559360.0000 - mae: 4784770.5000 - val_loss: 30129757618176.0000 - val_mae: 5007514.5000\n",
            "Epoch 15/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 25279233785856.0000 - mae: 4700911.5000 - val_loss: 30129698897920.0000 - val_mae: 5007509.5000\n",
            "Epoch 16/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 26540815417344.0000 - mae: 4819326.0000 - val_loss: 30129633886208.0000 - val_mae: 5007503.5000\n",
            "Epoch 17/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 24933748965376.0000 - mae: 4690429.0000 - val_loss: 30129554194432.0000 - val_mae: 5007496.0000\n",
            "Epoch 18/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 24246529032192.0000 - mae: 4626966.5000 - val_loss: 30129466114048.0000 - val_mae: 5007488.0000\n",
            "Epoch 19/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 26148899651584.0000 - mae: 4770437.0000 - val_loss: 30129367547904.0000 - val_mae: 5007478.5000\n",
            "Epoch 20/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24870238814208.0000 - mae: 4672346.5000 - val_loss: 30129250107392.0000 - val_mae: 5007467.5000\n",
            "Epoch 21/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24755361021952.0000 - mae: 4670248.0000 - val_loss: 30129115889664.0000 - val_mae: 5007455.0000\n",
            "Epoch 22/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 26222574698496.0000 - mae: 4810564.0000 - val_loss: 30128964894720.0000 - val_mae: 5007441.0000\n",
            "Epoch 23/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 26225525391360.0000 - mae: 4794304.0000 - val_loss: 30128790831104.0000 - val_mae: 5007425.0000\n",
            "Epoch 24/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 25325641662464.0000 - mae: 4728171.5000 - val_loss: 30128602087424.0000 - val_mae: 5007407.0000\n",
            "Epoch 25/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 25722739490816.0000 - mae: 4757741.0000 - val_loss: 30128386080768.0000 - val_mae: 5007387.5000\n",
            "Epoch 26/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 25687347953664.0000 - mae: 4726513.0000 - val_loss: 30128140713984.0000 - val_mae: 5007365.5000\n",
            "Epoch 27/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24385396146176.0000 - mae: 4634518.0000 - val_loss: 30127870181376.0000 - val_mae: 5007340.0000\n",
            "Epoch 28/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 25984732495872.0000 - mae: 4744421.0000 - val_loss: 30127574482944.0000 - val_mae: 5007312.5000\n",
            "Epoch 29/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25007566618624.0000 - mae: 4697752.5000 - val_loss: 30127245230080.0000 - val_mae: 5007282.5000\n",
            "Epoch 30/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 26110387552256.0000 - mae: 4782308.0000 - val_loss: 30126882422784.0000 - val_mae: 5007248.5000\n",
            "Epoch 31/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 24890960773120.0000 - mae: 4674451.0000 - val_loss: 30126479769600.0000 - val_mae: 5007211.5000\n",
            "Epoch 32/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24224542490624.0000 - mae: 4631114.5000 - val_loss: 30126035173376.0000 - val_mae: 5007170.5000\n",
            "Epoch 33/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24762988363776.0000 - mae: 4667784.0000 - val_loss: 30125554925568.0000 - val_mae: 5007126.5000\n",
            "Epoch 34/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24757856632832.0000 - mae: 4664372.0000 - val_loss: 30125026443264.0000 - val_mae: 5007077.0000\n",
            "Epoch 35/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24679297318912.0000 - mae: 4658343.5000 - val_loss: 30124458115072.0000 - val_mae: 5007024.5000\n",
            "Epoch 36/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25134001815552.0000 - mae: 4710876.5000 - val_loss: 30123828969472.0000 - val_mae: 5006966.5000\n",
            "Epoch 37/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25084613885952.0000 - mae: 4675989.0000 - val_loss: 30123151589376.0000 - val_mae: 5006904.5000\n",
            "Epoch 38/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 24562431426560.0000 - mae: 4663972.0000 - val_loss: 30122411294720.0000 - val_mae: 5006836.5000\n",
            "Epoch 39/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24380258123776.0000 - mae: 4643262.0000 - val_loss: 30121620668416.0000 - val_mae: 5006763.0000\n",
            "Epoch 40/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25396143718400.0000 - mae: 4724272.0000 - val_loss: 30120760836096.0000 - val_mae: 5006683.5000\n",
            "Epoch 41/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24805038358528.0000 - mae: 4670195.5000 - val_loss: 30119827603456.0000 - val_mae: 5006598.0000\n",
            "Epoch 42/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25687039672320.0000 - mae: 4729571.5000 - val_loss: 30118827261952.0000 - val_mae: 5006505.5000\n",
            "Epoch 43/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 24768870875136.0000 - mae: 4680185.5000 - val_loss: 30117747228672.0000 - val_mae: 5006406.0000\n",
            "Epoch 44/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 25528782290944.0000 - mae: 4749418.0000 - val_loss: 30116593795072.0000 - val_mae: 5006299.5000\n",
            "Epoch 45/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 26075795030016.0000 - mae: 4791858.0000 - val_loss: 30115364864000.0000 - val_mae: 5006185.5000\n",
            "Epoch 46/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24919167467520.0000 - mae: 4678486.5000 - val_loss: 30114035269632.0000 - val_mae: 5006063.5000\n",
            "Epoch 47/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23689984737280.0000 - mae: 4570759.5000 - val_loss: 30112590331904.0000 - val_mae: 5005930.5000\n",
            "Epoch 48/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 24771567812608.0000 - mae: 4674292.0000 - val_loss: 30111084576768.0000 - val_mae: 5005791.0000\n",
            "Epoch 49/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 26123175985152.0000 - mae: 4769779.0000 - val_loss: 30109494935552.0000 - val_mae: 5005644.5000\n",
            "Epoch 50/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 25477750194176.0000 - mae: 4695990.0000 - val_loss: 30107768979456.0000 - val_mae: 5005485.0000\n",
            "Epoch 51/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 25134735818752.0000 - mae: 4691887.0000 - val_loss: 30105927680000.0000 - val_mae: 5005315.5000\n",
            "Epoch 52/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 26765653180416.0000 - mae: 4824341.0000 - val_loss: 30104006688768.0000 - val_mae: 5005138.0000\n",
            "Epoch 53/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24881758470144.0000 - mae: 4675309.0000 - val_loss: 30101920022528.0000 - val_mae: 5004945.5000\n",
            "Epoch 54/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 25530980106240.0000 - mae: 4713943.5000 - val_loss: 30099726401536.0000 - val_mae: 5004743.0000\n",
            "Epoch 55/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 26159230222336.0000 - mae: 4798566.5000 - val_loss: 30097406951424.0000 - val_mae: 5004529.5000\n",
            "Epoch 56/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 25648034742272.0000 - mae: 4761083.5000 - val_loss: 30094932312064.0000 - val_mae: 5004301.5000\n",
            "Epoch 57/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 24691133644800.0000 - mae: 4660837.0000 - val_loss: 30092315066368.0000 - val_mae: 5004060.0000\n",
            "Epoch 58/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 25353225502720.0000 - mae: 4724859.5000 - val_loss: 30089538437120.0000 - val_mae: 5003804.0000\n",
            "Epoch 59/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 25048853250048.0000 - mae: 4714855.0000 - val_loss: 30086615007232.0000 - val_mae: 5003534.0000\n",
            "Epoch 60/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24414710136832.0000 - mae: 4625534.0000 - val_loss: 30083521708032.0000 - val_mae: 5003249.5000\n",
            "Epoch 61/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24551266189312.0000 - mae: 4654707.5000 - val_loss: 30080275316736.0000 - val_mae: 5002949.5000\n",
            "Epoch 62/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 24943326658560.0000 - mae: 4701104.0000 - val_loss: 30076838084608.0000 - val_mae: 5002633.0000\n",
            "Epoch 63/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 25717664382976.0000 - mae: 4756666.0000 - val_loss: 30073251954688.0000 - val_mae: 5002301.5000\n",
            "Epoch 64/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 25215729926144.0000 - mae: 4699176.0000 - val_loss: 30069462401024.0000 - val_mae: 5001952.5000\n",
            "Epoch 65/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 25417519988736.0000 - mae: 4742159.5000 - val_loss: 30065488297984.0000 - val_mae: 5001584.5000\n",
            "Epoch 66/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 25607746355200.0000 - mae: 4731055.5000 - val_loss: 30061293993984.0000 - val_mae: 5001198.0000\n",
            "Epoch 67/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 24523713806336.0000 - mae: 4628957.0000 - val_loss: 30056860614656.0000 - val_mae: 5000788.5000\n",
            "Epoch 68/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 25311620104192.0000 - mae: 4720850.5000 - val_loss: 30052278337536.0000 - val_mae: 5000365.0000\n",
            "Epoch 69/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 23675868807168.0000 - mae: 4581927.0000 - val_loss: 30047377293312.0000 - val_mae: 4999912.5000\n",
            "Epoch 70/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 27073735294976.0000 - mae: 4830147.5000 - val_loss: 30042390265856.0000 - val_mae: 4999451.0000\n",
            "Epoch 71/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 26155098832896.0000 - mae: 4776950.0000 - val_loss: 30037078179840.0000 - val_mae: 4998960.0000\n",
            "Epoch 72/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 24796127559680.0000 - mae: 4664498.0000 - val_loss: 30031466201088.0000 - val_mae: 4998442.5000\n",
            "Epoch 73/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 24044164349952.0000 - mae: 4600822.5000 - val_loss: 30025608855552.0000 - val_mae: 4997901.0000\n",
            "Epoch 74/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24843915362304.0000 - mae: 4674789.0000 - val_loss: 30019541794816.0000 - val_mae: 4997340.0000\n",
            "Epoch 75/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 25204843610112.0000 - mae: 4693266.0000 - val_loss: 30013158064128.0000 - val_mae: 4996750.0000\n",
            "Epoch 76/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25906387091456.0000 - mae: 4757222.0000 - val_loss: 30006543646720.0000 - val_mae: 4996138.5000\n",
            "Epoch 77/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 26824356659200.0000 - mae: 4836173.0000 - val_loss: 29999683862528.0000 - val_mae: 4995503.5000\n",
            "Epoch 78/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 25401030082560.0000 - mae: 4746999.5000 - val_loss: 29992408842240.0000 - val_mae: 4994831.5000\n",
            "Epoch 79/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 26031731769344.0000 - mae: 4792200.0000 - val_loss: 29984863289344.0000 - val_mae: 4994133.0000\n",
            "Epoch 80/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25195297374208.0000 - mae: 4728289.0000 - val_loss: 29976975900672.0000 - val_mae: 4993404.0000\n",
            "Epoch 81/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 25372487843840.0000 - mae: 4725653.0000 - val_loss: 29968752967680.0000 - val_mae: 4992643.5000\n",
            "Epoch 82/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 25289696477184.0000 - mae: 4693245.0000 - val_loss: 29960175616000.0000 - val_mae: 4991849.5000\n",
            "Epoch 83/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 25403269840896.0000 - mae: 4725364.5000 - val_loss: 29951287885824.0000 - val_mae: 4991027.0000\n",
            "Epoch 84/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 25547757322240.0000 - mae: 4719189.5000 - val_loss: 29941970239488.0000 - val_mae: 4990165.5000\n",
            "Epoch 85/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 25899474878464.0000 - mae: 4760702.0000 - val_loss: 29932344311808.0000 - val_mae: 4989274.5000\n",
            "Epoch 86/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 24793103466496.0000 - mae: 4679917.0000 - val_loss: 29922233942016.0000 - val_mae: 4988341.0000\n",
            "Epoch 87/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 24947703414784.0000 - mae: 4698717.0000 - val_loss: 29911743987712.0000 - val_mae: 4987371.0000\n",
            "Epoch 88/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 25355437998080.0000 - mae: 4727291.0000 - val_loss: 29900931072000.0000 - val_mae: 4986370.5000\n",
            "Epoch 89/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 24194102329344.0000 - mae: 4652438.0000 - val_loss: 29889583382528.0000 - val_mae: 4985321.0000\n",
            "Epoch 90/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 25510631440384.0000 - mae: 4737143.0000 - val_loss: 29878000812032.0000 - val_mae: 4984248.5000\n",
            "Epoch 91/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 24725090729984.0000 - mae: 4679035.0000 - val_loss: 29865763930112.0000 - val_mae: 4983117.5000\n",
            "Epoch 92/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 24741846974464.0000 - mae: 4676805.5000 - val_loss: 29853170532352.0000 - val_mae: 4981951.0000\n",
            "Epoch 93/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 24711048200192.0000 - mae: 4662442.5000 - val_loss: 29840092692480.0000 - val_mae: 4980739.5000\n",
            "Epoch 94/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 25020743024640.0000 - mae: 4686643.5000 - val_loss: 29826582839296.0000 - val_mae: 4979487.5000\n",
            "Epoch 95/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 24726432907264.0000 - mae: 4665373.5000 - val_loss: 29812450131968.0000 - val_mae: 4978180.5000\n",
            "Epoch 96/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 25092270587904.0000 - mae: 4698066.5000 - val_loss: 29797931548672.0000 - val_mae: 4976836.0000\n",
            "Epoch 97/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 23443177209856.0000 - mae: 4544507.0000 - val_loss: 29782746071040.0000 - val_mae: 4975430.5000\n",
            "Epoch 98/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24176064724992.0000 - mae: 4596966.0000 - val_loss: 29767074054144.0000 - val_mae: 4973979.0000\n",
            "Epoch 99/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 24383439503360.0000 - mae: 4640575.5000 - val_loss: 29750913400832.0000 - val_mae: 4972482.0000\n",
            "Epoch 100/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 24114005803008.0000 - mae: 4606069.0000 - val_loss: 29734157156352.0000 - val_mae: 4970927.5000\n",
            "Epoch 101/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 26764678004736.0000 - mae: 4820485.0000 - val_loss: 29717163933696.0000 - val_mae: 4969348.0000\n",
            "Epoch 102/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24554728587264.0000 - mae: 4644945.0000 - val_loss: 29699195535360.0000 - val_mae: 4967682.0000\n",
            "Epoch 103/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 26419262390272.0000 - mae: 4783083.0000 - val_loss: 29680807706624.0000 - val_mae: 4965975.5000\n",
            "Epoch 104/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24883048218624.0000 - mae: 4684341.5000 - val_loss: 29661954310144.0000 - val_mae: 4964221.5000\n",
            "Epoch 105/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 25010112561152.0000 - mae: 4694854.5000 - val_loss: 29642266247168.0000 - val_mae: 4962394.5000\n",
            "Epoch 106/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 25122782052352.0000 - mae: 4699999.5000 - val_loss: 29621779169280.0000 - val_mae: 4960491.5000\n",
            "Epoch 107/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24576396361728.0000 - mae: 4667852.0000 - val_loss: 29600763609088.0000 - val_mae: 4958538.0000\n",
            "Epoch 108/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25253015191552.0000 - mae: 4694544.5000 - val_loss: 29579219566592.0000 - val_mae: 4956533.5000\n",
            "Epoch 109/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23982187216896.0000 - mae: 4602687.0000 - val_loss: 29556801011712.0000 - val_mae: 4954449.0000\n",
            "Epoch 110/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24204059607040.0000 - mae: 4615860.0000 - val_loss: 29533761699840.0000 - val_mae: 4952306.5000\n",
            "Epoch 111/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 25021720297472.0000 - mae: 4681602.0000 - val_loss: 29510145671168.0000 - val_mae: 4950110.0000\n",
            "Epoch 112/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24503285448704.0000 - mae: 4637866.5000 - val_loss: 29485632061440.0000 - val_mae: 4947826.0000\n",
            "Epoch 113/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 24850682871808.0000 - mae: 4676176.0000 - val_loss: 29460405420032.0000 - val_mae: 4945475.0000\n",
            "Epoch 114/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 25802454335488.0000 - mae: 4748963.0000 - val_loss: 29434388152320.0000 - val_mae: 4943052.5000\n",
            "Epoch 115/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 25127987183616.0000 - mae: 4695615.5000 - val_loss: 29407695601664.0000 - val_mae: 4940560.5000\n",
            "Epoch 116/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 23940143513600.0000 - mae: 4590351.0000 - val_loss: 29379788800000.0000 - val_mae: 4937961.0000\n",
            "Epoch 117/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 23838937055232.0000 - mae: 4587679.5000 - val_loss: 29351171063808.0000 - val_mae: 4935291.5000\n",
            "Epoch 118/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 23419009630208.0000 - mae: 4528218.5000 - val_loss: 29321842393088.0000 - val_mae: 4932551.0000\n",
            "Epoch 119/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 22469742166016.0000 - mae: 4464453.5000 - val_loss: 29291479826432.0000 - val_mae: 4929713.5000\n",
            "Epoch 120/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25060878319616.0000 - mae: 4701047.0000 - val_loss: 29260662177792.0000 - val_mae: 4926829.0000\n",
            "Epoch 121/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 24755677691904.0000 - mae: 4646716.5000 - val_loss: 29228928073728.0000 - val_mae: 4923857.5000\n",
            "Epoch 122/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 25900659769344.0000 - mae: 4762159.5000 - val_loss: 29196900368384.0000 - val_mae: 4920854.5000\n",
            "Epoch 123/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24950987554816.0000 - mae: 4671746.0000 - val_loss: 29163092180992.0000 - val_mae: 4917689.5000\n",
            "Epoch 124/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24447666880512.0000 - mae: 4641250.0000 - val_loss: 29128539504640.0000 - val_mae: 4914452.5000\n",
            "Epoch 125/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 24924131426304.0000 - mae: 4670382.5000 - val_loss: 29092783063040.0000 - val_mae: 4911102.0000\n",
            "Epoch 126/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 25393889280000.0000 - mae: 4693796.5000 - val_loss: 29056311492608.0000 - val_mae: 4907678.5000\n",
            "Epoch 127/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 24111814279168.0000 - mae: 4596287.5000 - val_loss: 29018457899008.0000 - val_mae: 4904128.0000\n",
            "Epoch 128/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24470605529088.0000 - mae: 4626128.5000 - val_loss: 28979824164864.0000 - val_mae: 4900496.5000\n",
            "Epoch 129/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 24415953747968.0000 - mae: 4619427.5000 - val_loss: 28940271878144.0000 - val_mae: 4896776.0000\n",
            "Epoch 130/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24170654072832.0000 - mae: 4603697.5000 - val_loss: 28899568254976.0000 - val_mae: 4892946.0000\n",
            "Epoch 131/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 23827474022400.0000 - mae: 4556180.5000 - val_loss: 28857614729216.0000 - val_mae: 4888996.5000\n",
            "Epoch 132/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 24533750775808.0000 - mae: 4601262.5000 - val_loss: 28814975434752.0000 - val_mae: 4884976.0000\n",
            "Epoch 133/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23236402216960.0000 - mae: 4522123.5000 - val_loss: 28770614378496.0000 - val_mae: 4880798.0000\n",
            "Epoch 134/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23647114756096.0000 - mae: 4533172.5000 - val_loss: 28725378809856.0000 - val_mae: 4876531.5000\n",
            "Epoch 135/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 24327917404160.0000 - mae: 4623657.5000 - val_loss: 28679275020288.0000 - val_mae: 4872174.5000\n",
            "Epoch 136/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22929930715136.0000 - mae: 4482223.5000 - val_loss: 28631535452160.0000 - val_mae: 4867664.5000\n",
            "Epoch 137/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 23526318800896.0000 - mae: 4537698.5000 - val_loss: 28583124795392.0000 - val_mae: 4863083.5000\n",
            "Epoch 138/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 23838473584640.0000 - mae: 4548080.5000 - val_loss: 28533590065152.0000 - val_mae: 4858391.0000\n",
            "Epoch 139/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 25087157731328.0000 - mae: 4672541.0000 - val_loss: 28483302457344.0000 - val_mae: 4853618.0000\n",
            "Epoch 140/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23691855396864.0000 - mae: 4544051.0000 - val_loss: 28430456324096.0000 - val_mae: 4848608.5000\n",
            "Epoch 141/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23471568453632.0000 - mae: 4547416.5000 - val_loss: 28376922324992.0000 - val_mae: 4843525.0000\n",
            "Epoch 142/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23079371669504.0000 - mae: 4477165.0000 - val_loss: 28321746255872.0000 - val_mae: 4838281.5000\n",
            "Epoch 143/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23942154682368.0000 - mae: 4560287.0000 - val_loss: 28265282535424.0000 - val_mae: 4832910.5000\n",
            "Epoch 144/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 23983755886592.0000 - mae: 4574505.5000 - val_loss: 28208206446592.0000 - val_mae: 4827468.5000\n",
            "Epoch 145/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 22959074836480.0000 - mae: 4476344.5000 - val_loss: 28148689272832.0000 - val_mae: 4821799.5000\n",
            "Epoch 146/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 23545430147072.0000 - mae: 4534343.5000 - val_loss: 28087699898368.0000 - val_mae: 4815990.5000\n",
            "Epoch 147/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 23167594659840.0000 - mae: 4496219.5000 - val_loss: 28026112835584.0000 - val_mae: 4810096.0000\n",
            "Epoch 148/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 22805538144256.0000 - mae: 4459253.5000 - val_loss: 27963001143296.0000 - val_mae: 4804051.5000\n",
            "Epoch 149/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 22278855196672.0000 - mae: 4419757.5000 - val_loss: 27898310295552.0000 - val_mae: 4797849.0000\n",
            "Epoch 150/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 24032074268672.0000 - mae: 4603053.5000 - val_loss: 27833319555072.0000 - val_mae: 4791609.5000\n",
            "Epoch 151/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23380602388480.0000 - mae: 4526506.0000 - val_loss: 27765877243904.0000 - val_mae: 4785129.0000\n",
            "Epoch 152/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 23169096220672.0000 - mae: 4495693.5000 - val_loss: 27696939663360.0000 - val_mae: 4778502.5000\n",
            "Epoch 153/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22287963127808.0000 - mae: 4407131.0000 - val_loss: 27626106257408.0000 - val_mae: 4771686.0000\n",
            "Epoch 154/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22767751659520.0000 - mae: 4470761.5000 - val_loss: 27553892925440.0000 - val_mae: 4764721.5000\n",
            "Epoch 155/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 22702979022848.0000 - mae: 4458129.5000 - val_loss: 27480490508288.0000 - val_mae: 4757631.5000\n",
            "Epoch 156/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23049084600320.0000 - mae: 4457446.5000 - val_loss: 27404772835328.0000 - val_mae: 4750312.0000\n",
            "Epoch 157/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 22860982648832.0000 - mae: 4461780.5000 - val_loss: 27327748636672.0000 - val_mae: 4742862.0000\n",
            "Epoch 158/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23317455044608.0000 - mae: 4486734.0000 - val_loss: 27248667131904.0000 - val_mae: 4735206.0000\n",
            "Epoch 159/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 21691891712000.0000 - mae: 4349877.0000 - val_loss: 27167987597312.0000 - val_mae: 4727366.0000\n",
            "Epoch 160/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 23830852534272.0000 - mae: 4551529.5000 - val_loss: 27087691841536.0000 - val_mae: 4719534.0000\n",
            "Epoch 161/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22170377912320.0000 - mae: 4399137.0000 - val_loss: 27003705098240.0000 - val_mae: 4711347.0000\n",
            "Epoch 162/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 21474503032832.0000 - mae: 4329732.0000 - val_loss: 26917770100736.0000 - val_mae: 4702958.5000\n",
            "Epoch 163/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 22058448715776.0000 - mae: 4370351.5000 - val_loss: 26831738634240.0000 - val_mae: 4694537.5000\n",
            "Epoch 164/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 22072371707904.0000 - mae: 4372479.0000 - val_loss: 26742701948928.0000 - val_mae: 4685818.5000\n",
            "Epoch 165/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 23172665573376.0000 - mae: 4466786.5000 - val_loss: 26652729933824.0000 - val_mae: 4676980.5000\n",
            "Epoch 166/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 22924476022784.0000 - mae: 4458802.5000 - val_loss: 26560843218944.0000 - val_mae: 4667935.0000\n",
            "Epoch 167/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 22763410554880.0000 - mae: 4458837.5000 - val_loss: 26467167633408.0000 - val_mae: 4658707.0000\n",
            "Epoch 168/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 21162201448448.0000 - mae: 4309502.0000 - val_loss: 26370423914496.0000 - val_mae: 4649162.0000\n",
            "Epoch 169/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 20582829654016.0000 - mae: 4242949.0000 - val_loss: 26271778078720.0000 - val_mae: 4639415.0000\n",
            "Epoch 170/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 22272089784320.0000 - mae: 4379464.0000 - val_loss: 26172199010304.0000 - val_mae: 4629545.0000\n",
            "Epoch 171/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 21169082204160.0000 - mae: 4305294.5000 - val_loss: 26070258548736.0000 - val_mae: 4619426.5000\n",
            "Epoch 172/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 21608485879808.0000 - mae: 4342317.5000 - val_loss: 25967477129216.0000 - val_mae: 4609195.5000\n",
            "Epoch 173/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 21847814963200.0000 - mae: 4345623.0000 - val_loss: 25862623723520.0000 - val_mae: 4598729.0000\n",
            "Epoch 174/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 20779378933760.0000 - mae: 4274460.0000 - val_loss: 25753898975232.0000 - val_mae: 4587875.0000\n",
            "Epoch 175/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 20355863281664.0000 - mae: 4217193.5000 - val_loss: 25644150816768.0000 - val_mae: 4576880.0000\n",
            "Epoch 176/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20789931802624.0000 - mae: 4251919.5000 - val_loss: 25533408608256.0000 - val_mae: 4565750.5000\n",
            "Epoch 177/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20919235903488.0000 - mae: 4268060.5000 - val_loss: 25419124310016.0000 - val_mae: 4554264.0000\n",
            "Epoch 178/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21290985455616.0000 - mae: 4265209.0000 - val_loss: 25304277975040.0000 - val_mae: 4542667.0000\n",
            "Epoch 179/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 20995045851136.0000 - mae: 4245547.0000 - val_loss: 25186982166528.0000 - val_mae: 4530802.0000\n",
            "Epoch 180/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20990054629376.0000 - mae: 4251963.0000 - val_loss: 25067853447168.0000 - val_mae: 4518716.5000\n",
            "Epoch 181/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 20879656353792.0000 - mae: 4263531.0000 - val_loss: 24946656935936.0000 - val_mae: 4506402.0000\n",
            "Epoch 182/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 21003497373696.0000 - mae: 4264776.0000 - val_loss: 24822117564416.0000 - val_mae: 4493710.5000\n",
            "Epoch 183/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20591568486400.0000 - mae: 4191598.0000 - val_loss: 24697007767552.0000 - val_mae: 4480915.0000\n",
            "Epoch 184/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 19841775828992.0000 - mae: 4183672.5000 - val_loss: 24568458641408.0000 - val_mae: 4467746.5000\n",
            "Epoch 185/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 20643770793984.0000 - mae: 4233818.0000 - val_loss: 24438338748416.0000 - val_mae: 4454388.5000\n",
            "Epoch 186/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 20898643968000.0000 - mae: 4260936.5000 - val_loss: 24306807472128.0000 - val_mae: 4440824.5000\n",
            "Epoch 187/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 20741261099008.0000 - mae: 4210192.5000 - val_loss: 24172042387456.0000 - val_mae: 4426887.0000\n",
            "Epoch 188/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 19474463850496.0000 - mae: 4087881.0000 - val_loss: 24034970435584.0000 - val_mae: 4412662.5000\n",
            "Epoch 189/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 20140989087744.0000 - mae: 4183265.7500 - val_loss: 23896635998208.0000 - val_mae: 4398259.0000\n",
            "Epoch 190/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 20377975652352.0000 - mae: 4180968.5000 - val_loss: 23756504301568.0000 - val_mae: 4383622.0000\n",
            "Epoch 191/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 19654921682944.0000 - mae: 4110360.7500 - val_loss: 23613273014272.0000 - val_mae: 4368610.0000\n",
            "Epoch 192/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 19990736535552.0000 - mae: 4134598.0000 - val_loss: 23468055724032.0000 - val_mae: 4353347.0000\n",
            "Epoch 193/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 19400082063360.0000 - mae: 4071598.2500 - val_loss: 23319443144704.0000 - val_mae: 4337683.5000\n",
            "Epoch 194/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 18763049074688.0000 - mae: 4034614.0000 - val_loss: 23168777453568.0000 - val_mae: 4321742.5000\n",
            "Epoch 195/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 18127714779136.0000 - mae: 3948650.7500 - val_loss: 23015758757888.0000 - val_mae: 4305499.5000\n",
            "Epoch 196/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 18472945844224.0000 - mae: 3985226.7500 - val_loss: 22861972504576.0000 - val_mae: 4289115.0000\n",
            "Epoch 197/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 19112625438720.0000 - mae: 4064579.0000 - val_loss: 22707215269888.0000 - val_mae: 4272541.0000\n",
            "Epoch 198/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 19260694855680.0000 - mae: 4053906.0000 - val_loss: 22548689453056.0000 - val_mae: 4255507.5000\n",
            "Epoch 199/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 18037417705472.0000 - mae: 3940143.2500 - val_loss: 22385845600256.0000 - val_mae: 4237964.0000\n",
            "Epoch 200/200\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 17857274445824.0000 - mae: 3938539.7500 - val_loss: 22221732970496.0000 - val_mae: 4220203.5000\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Mean Squared Error: 22221732970496.0\n",
            "Root Mean Absolute Error: 2054.3135106404766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load dataset\n",
        "dataset_url = \"/content/drive/MyDrive/Housing.csv\"\n",
        "df = pd.read_csv(dataset_url)\n",
        "\n",
        "# Assuming the **first** column is the target variable (housing price)\n",
        "X = df.drop(columns=df.columns[0])  # Drop the **first** variable column(likely 'price')\n",
        "y = df.iloc[:, 0].values #select the **first** column (likely 'price')as the target\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
        "\n",
        "# Create preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features) # sparse=False for compatibility with TensorFlow\n",
        "    ])\n",
        "\n",
        "# Create pipeline with preprocessor and model\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', Sequential([\n",
        "        Dense(18, activation='swish', input_shape=(preprocessor.fit_transform(X).shape[1],)),\n",
        "        Dense(26, activation='swish'),\n",
        "        Dense(20, activation='swish'),\n",
        "        Dense(15, activation='swish'),\n",
        "        Dense(1)  # Output layer\n",
        "    ]))\n",
        "])\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit and transform data using the pipeline\n",
        "\n",
        "# Fit and transform the preprocessor on the training data\n",
        "X_train_transformed = pipeline.named_steps['preprocessor'].fit_transform(X_train, y_train)\n",
        "\n",
        "# Transform the testing data using the fitted preprocessor\n",
        "X_test_transformed = pipeline.named_steps['preprocessor'].transform(X_test)\n",
        "\n",
        "# Compile the model before fitting # This line was moved up\n",
        "pipeline.named_steps['model'].compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "\n",
        "# Fit the model using the transformed training data\n",
        "pipeline.named_steps['model'].fit(X_train_transformed, y_train, epochs=200, batch_size=64, validation_data=(X_test_transformed, y_test))\n",
        "\n",
        "# Make predictions using the transformed testing data\n",
        "y_pred = pipeline.named_steps['model'].predict(X_test_transformed)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "#pipeline.named_steps['model'].fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_test, y_test)) # This line was removed because it was attempting to train on unprocessed data and was redundant\n",
        "\n",
        "\n",
        "# Evaluate model performance\n",
        "y_pred = pipeline.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmae = np.sqrt(mean_absolute_error(y_test, y_pred))\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Absolute Error: {rmae}\")\n",
        "\n",
        "# Save the model (save the entire pipeline)\n",
        "# !pip install joblib\n",
        "import joblib\n",
        "joblib.dump(pipeline, \"housing_price_pipeline.pkl\")\n",
        "\n",
        "# Load and deploy the model\n",
        "def predict_house_price(input_data):\n",
        "    loaded_pipeline = joblib.load(\"housing_price_pipeline.pkl\")\n",
        "    # Input data should be a pandas DataFrame with the same columns as the original data\n",
        "    input_df = pd.DataFrame([input_data])\n",
        "    prediction = loaded_pipeline.predict(input_df)\n",
        "    return prediction[0]\n",
        "\n",
        "# Example usage:\n",
        "# sample_input = X_test[0]  # Assuming X_test is a DataFrame or a dictionary-like object\n",
        "# predicted_price = predict_house_price(sample_input)\n",
        "# print(\"Predicted Price:\", predicted_price)"
      ]
    }
  ]
}
